{
  "source_id": "marktechpost",
  "source_name": "MarkTechPost",
  "collected_at": "2025-10-17T16:34:02.594435",
  "article_count": 10,
  "articles": [
    {
      "content_id": "9f7b5d388e2986c862bc51e0a904cfe9",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Baidu\u2019s PaddlePaddle Team Releases PaddleOCR-VL (0.9B): a NaViT-style + ERNIE-4.5-0.3B VLM Targeting End-to-End Multilingual Document Parsing",
      "url": "https://www.marktechpost.com/2025/10/17/baidus-paddlepaddle-team-releases-paddleocr-vl-0-9b-a-navit-style-ernie-4-5-0-3b-vlm-targeting-end-to-end-multilingual-document-parsing/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-17T08:28:58",
      "fetched_at": "2025-10-17T16:34:02.593564",
      "content_type": "article",
      "content_text": "How do you convert complex, multilingual documents\u2014dense layouts, small scripts, formulas, charts, and handwriting\u2014into faithful structured Markdown/JSON with state-of-the-art accuracy while keeping inference latency and memory low enough for real deployments?Baidu\u2019s PaddlePaddle group has released PaddleOCR-VL, a 0.9B-parameter vision-language model designed for end-to-end document parsing across text, tables, formulas, charts, and handwriting. The core model [&#8230;]\nThe post Baidu\u2019s PaddlePaddle Team Releases PaddleOCR-VL (0.9B): a NaViT-style + ERNIE-4.5-0.3B VLM Targeting End-to-End Multilingual Document Parsing appeared first on MarkTechPost.",
      "content_length": 78,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "AI Paper Summary",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Machine Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        },
        {
          "term": "Vision Language Model",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75448",
        "guid": "https://www.marktechpost.com/?p=75448"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "5d0b9e9ca63786a18fffc240a3a792f5",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Google AI Releases C2S-Scale 27B Model that Translate Complex Single-Cell Gene Expression Data into \u2018cell sentences\u2019 that LLMs can Understand",
      "url": "https://www.marktechpost.com/2025/10/17/google-ai-releases-c2s-scale-27b-model-that-translate-complex-single-cell-gene-expression-data-into-cell-sentences-that-llms-can-understand/",
      "author": "Michal Sutter",
      "published_at": "2025-10-17T07:42:22",
      "fetched_at": "2025-10-17T16:34:02.593586",
      "content_type": "article",
      "content_text": "A team of researchers from Google Research, Google DeepMind, and Yale released C2S-Scale 27B, a 27-billion-parameter foundation model for single-cell analysis built on Gemma-2. The model formalizes single-cell RNA-seq (scRNA-seq) profiles as \u201ccell sentences\u201d\u2014ordered lists of gene symbols\u2014so that a language model can natively parse and reason over cellular states. Beyond benchmarking gains, the research [&#8230;]\nThe post Google AI Releases C2S-Scale 27B Model that Translate Complex Single-Cell Gene Expression Data into &#8216;cell sentences&#8217; that LLMs can Understand appeared first on MarkTechPost.",
      "content_length": 82,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "AI Paper Summary",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Large Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Machine Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75443",
        "guid": "https://www.marktechpost.com/?p=75443"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "3e6ce05278b6304cfbc507e00a617504",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Qualifire AI Releases Rogue: An End-to-End Agentic AI Testing Framework, Evaluating the Performance of AI Agents",
      "url": "https://www.marktechpost.com/2025/10/17/qualifire-ai-releases-rogue-an-end-to-end-agentic-ai-testing-framework-evaluating-the-performance-of-ai-agents/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-17T07:05:21",
      "fetched_at": "2025-10-17T16:34:02.593600",
      "content_type": "article",
      "content_text": "Agentic systems are stochastic, context-dependent, and policy-bounded. Conventional QA\u2014unit tests, static prompts, or scalar \u201cLLM-as-a-judge\u201d scores\u2014fails to expose multi-turn vulnerabilities and provides weak audit trails. Developer teams need protocol-accurate conversations, explicit policy checks, and machine-readable evidence that can gate releases with confidence. Qualifire AI has open-sourced Rogue, a Python framework that evaluates AI agents over [&#8230;]\nThe post Qualifire AI Releases Rogue: An End-to-End Agentic AI Testing Framework, Evaluating the Performance of AI Agents appeared first on MarkTechPost.",
      "content_length": 78,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Agents",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Open Source",
          "scheme": null,
          "label": null
        },
        {
          "term": "Promote",
          "scheme": null,
          "label": null
        },
        {
          "term": "Sponsored",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75424",
        "guid": "https://www.marktechpost.com/?p=75424"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "841f38956d2ea9fd2e86fa22a88b4c3c",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "A Coding Guide to Build an AI-Powered Cryptographic Agent System with Hybrid Encryption, Digital Signatures, and Adaptive Security Intelligence",
      "url": "https://www.marktechpost.com/2025/10/16/a-coding-guide-to-build-an-ai-powered-cryptographic-agent-system-with-hybrid-encryption-digital-signatures-and-adaptive-security-intelligence/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-17T06:55:40",
      "fetched_at": "2025-10-17T16:34:02.593613",
      "content_type": "article",
      "content_text": "In this tutorial, we build an AI-powered cryptographic agent system that combines the strength of classical encryption with adaptive intelligence. We design agents capable of performing hybrid encryption with RSA and AES, generating digital signatures, detecting anomalies in message patterns, and intelligently recommending key rotations. As we progress, we witness these autonomous agents securely establish [&#8230;]\nThe post A Coding Guide to Build an AI-Powered Cryptographic Agent System with Hybrid Encryption, Digital Signatures, and Adaptive Security Intelligence appeared first on MarkTechPost.",
      "content_length": 81,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Agents",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tutorials",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75438",
        "guid": "https://www.marktechpost.com/?p=75438"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "bba7e9c16b827bde248f4fcd36c69fc3",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "QeRL: NVFP4-Quantized Reinforcement Learning (RL) Brings 32B LLM Training to a Single H100\u2014While Improving Exploration",
      "url": "https://www.marktechpost.com/2025/10/15/qerl-nvfp4-quantized-reinforcement-learning-rl-brings-32b-llm-training-to-a-single-h100-while-improving-exploration/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-16T04:28:31",
      "fetched_at": "2025-10-17T16:34:02.593625",
      "content_type": "article",
      "content_text": "What would you build if you could run Reinforcement Learning (RL) post-training on a 32B LLM in 4-bit NVFP4\u2014on a single H100\u2014with BF16-level accuracy and 1.2\u20131.5\u00d7 step speedups? NVIDIA researchers (with collaborators from MIT, HKU, and Tsinghua) have open-sourced QeRL (Quantization-enhanced Reinforcement Learning), a training framework that pushes Reinforcement Learning (RL) post-training into 4-bit FP4 [&#8230;]\nThe post QeRL: NVFP4-Quantized Reinforcement Learning (RL) Brings 32B LLM Training to a Single H100\u2014While Improving Exploration appeared first on MarkTechPost.",
      "content_length": 77,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "AI Paper Summary",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Machine Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75411",
        "guid": "https://www.marktechpost.com/?p=75411"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "8775016b80c9bdfb7f703b9bc93f5722",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Building a Context-Folding LLM Agent for Long-Horizon Reasoning with Memory Compression and Tool Use",
      "url": "https://www.marktechpost.com/2025/10/15/building-a-context-folding-llm-agent-for-long-horizon-reasoning-with-memory-compression-and-tool-use/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-16T01:52:28",
      "fetched_at": "2025-10-17T16:34:02.593637",
      "content_type": "article",
      "content_text": "In this tutorial, we explore how to build a Context-Folding LLM Agent that efficiently solves long, complex tasks by intelligently managing limited context. We design the agent to break down a large task into smaller subtasks, perform reasoning or calculations when needed, and then fold each completed sub-trajectory into concise summaries. By doing this, we [&#8230;]\nThe post Building a Context-Folding LLM Agent for Long-Horizon Reasoning with Memory Compression and Tool Use appeared first on MarkTechPost.",
      "content_length": 76,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Agents",
          "scheme": null,
          "label": null
        },
        {
          "term": "Context Engineering",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tutorials",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75408",
        "guid": "https://www.marktechpost.com/?p=75408"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "f8944349fd6503d30a475c4e59468518",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Anthropic Launches Claude Haiku 4.5: Small AI Model that Delivers Sonnet-4-Level Coding Performance at One-Third the Cost and more than Twice the Speed",
      "url": "https://www.marktechpost.com/2025/10/15/anthropic-launches-claude-haiku-4-5-small-ai-model-that-delivers-sonnet-4-level-coding-performance-at-one-third-the-cost-and-more-than-twice-the-speed/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-15T17:52:49",
      "fetched_at": "2025-10-17T16:34:02.593649",
      "content_type": "article",
      "content_text": "Anthropic released Claude Haiku 4.5, a latency-optimized \u201csmall\u201d model that delivers similar levels of coding performance to Claude Sonnet 4 while running more than twice as fast at one-third the cost. The model is immediately available via Anthropic\u2019s API and in partner catalogs on Amazon Bedrock and Google Cloud Vertex AI. Pricing is $1/MTok input [&#8230;]\nThe post Anthropic Launches Claude Haiku 4.5: Small AI Model that Delivers Sonnet-4-Level Coding Performance at One-Third the Cost and more than Twice the Speed appeared first on MarkTechPost.",
      "content_length": 85,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Small Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75401",
        "guid": "https://www.marktechpost.com/?p=75401"
      },
      "raw_score": 0.6499999999999999
    },
    {
      "content_id": "47c978611259700c4cc8c3c1e942916b",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Meta AI\u2019s \u2018Early Experience\u2019 Trains Language Agents without Rewards\u2014and Outperforms Imitation Learning",
      "url": "https://www.marktechpost.com/2025/10/15/meta-ais-early-experience-trains-language-agents-without-rewards-and-outperforms-imitation-learning/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-15T09:32:54",
      "fetched_at": "2025-10-17T16:34:02.593660",
      "content_type": "article",
      "content_text": "How would your agent stack change if a policy could train purely from its own outcome-grounded rollouts\u2014no rewards, no demos\u2014yet beat imitation learning across eight benchmarks? Meta Superintelligence Labs propose &#8216;Early Experience&#8216;, a reward-free training approach that improves policy learning in language agents without large human demonstration sets and without reinforcement learning (RL) in the [&#8230;]\nThe post Meta AI\u2019s &#8216;Early Experience&#8217; Trains Language Agents without Rewards\u2014and Outperforms Imitation Learning appeared first on MarkTechPost.",
      "content_length": 74,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Agents",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Paper Summary",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Large Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Machine Learning",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75394",
        "guid": "https://www.marktechpost.com/?p=75394"
      },
      "raw_score": 0.63
    },
    {
      "content_id": "e9c3093015c1662bbe42b585063742d7",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Alibaba\u2019s Qwen AI Releases Compact Dense Qwen3-VL 4B/8B (Instruct & Thinking) With FP8 Checkpoints",
      "url": "https://www.marktechpost.com/2025/10/14/alibabas-qwen-ai-releases-compact-dense-qwen3-vl-4b-8b-instruct-thinking-with-fp8-checkpoints/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-15T02:14:53",
      "fetched_at": "2025-10-17T16:34:02.593671",
      "content_type": "article",
      "content_text": "Do you actually need a giant VLM when dense Qwen3-VL 4B/8B (Instruct/Thinking) with FP8 runs in low VRAM yet retains 256K\u21921M context and the full capability surface? Alibaba\u2019s Qwen team has expanded its multimodal lineup with dense Qwen3-VL models at 4B and 8B scales, each shipping in two task profiles\u2014Instruct and Thinking\u2014plus FP8-quantized checkpoints for [&#8230;]\nThe post Alibaba\u2019s Qwen AI Releases Compact Dense Qwen3-VL 4B/8B (Instruct &amp; Thinking) With FP8 Checkpoints appeared first on MarkTechPost.",
      "content_length": 76,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Large Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Open Source",
          "scheme": null,
          "label": null
        },
        {
          "term": "Small Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        },
        {
          "term": "Vision Language Model",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75385",
        "guid": "https://www.marktechpost.com/?p=75385"
      },
      "raw_score": 0.63
    },
    {
      "content_id": "3e674a53a5b7720feeba4f69fe03b2ef",
      "source_id": "marktechpost",
      "source_name": "MarkTechPost",
      "title": "Andrej Karpathy Releases \u2018nanochat\u2019: A Minimal, End-to-End ChatGPT-Style Pipeline You Can Train in ~4 Hours for ~$100",
      "url": "https://www.marktechpost.com/2025/10/14/andrej-karpathy-releases-nanochat-a-minimal-end-to-end-chatgpt-style-pipeline-you-can-train-in-4-hours-for-100/",
      "author": "Asif Razzaq",
      "published_at": "2025-10-14T17:40:10",
      "fetched_at": "2025-10-17T16:34:02.593702",
      "content_type": "article",
      "content_text": "Andrej Karpathy has open-sourced nanochat, a compact, dependency-light codebase that implements a full ChatGPT-style stack\u2014from tokenizer training to web UI inference\u2014aimed at reproducible, hackable LLM training on a single multi-GPU node. The repo provides a single-script \u201cspeedrun\u201d that executes the full loop: tokenization, base pretraining, mid-training on chat/multiple-choice/tool-use data, Supervised Finetuning (SFT), optional RL on [&#8230;]\nThe post Andrej Karpathy Releases &#8216;nanochat&#8217;: A Minimal, End-to-End ChatGPT-Style Pipeline You Can Train in ~4 Hours for ~$100 appeared first on MarkTechPost.",
      "content_length": 79,
      "category": "ai_news",
      "priority": "high",
      "base_weight": 0.6,
      "tags": [
        {
          "term": "Agentic AI",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Shorts",
          "scheme": null,
          "label": null
        },
        {
          "term": "AI Tool",
          "scheme": null,
          "label": null
        },
        {
          "term": "Applications",
          "scheme": null,
          "label": null
        },
        {
          "term": "Artificial Intelligence",
          "scheme": null,
          "label": null
        },
        {
          "term": "Editors Pick",
          "scheme": null,
          "label": null
        },
        {
          "term": "Language Model",
          "scheme": null,
          "label": null
        },
        {
          "term": "New Releases",
          "scheme": null,
          "label": null
        },
        {
          "term": "Open Source",
          "scheme": null,
          "label": null
        },
        {
          "term": "Staff",
          "scheme": null,
          "label": null
        },
        {
          "term": "Tech News",
          "scheme": null,
          "label": null
        },
        {
          "term": "Technology",
          "scheme": null,
          "label": null
        }
      ],
      "raw_entry": {
        "id": "https://www.marktechpost.com/?p=75381",
        "guid": "https://www.marktechpost.com/?p=75381"
      },
      "raw_score": 0.63
    }
  ]
}